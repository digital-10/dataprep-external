# -Ddataprep.data.home=/Users/motive/Documents/dataprep -Ddataprep.data.semantic=/Users/motive/Documents/dataprep/common/semantic -Dserver.port=9171

#
# ============================================================================
# Copyright (C) 2006-2018 Talend Inc. - www.talend.com
#
# This source code is available under agreement available at
# https://github.com/Talend/data-prep/blob/master/LICENSE
#
# You should have received a copy of the agreement
# along with this program; if not, write to Talend SA
# 9 rue Pages 92150 Suresnes, France
#
# ============================================================================
#

################################################################################

# 실행시 입력 또는 변경 
#dataprep.data.home=/Users/motive/Documents/dataprep
#dataprep.data.semantic=/Users/motive/Documents/dataprep/common/semantic
#server.port=8888
dataprep.node.no=0
dataprep.node.count=1
# 노드가 늘어날 때 변경 (service.url 로 변경) 
#dataprep.node.dataset.hosts = http://127.0.0.1:${server.port}
#dataprep.node.preparation.hosts = http://127.0.0.1:${server.port}
#dataprep.node.export.hosts = http://127.0.0.1:${server.port}
dataset.service.url=http://127.0.0.1:${server.port}
preparation.service.url=http://127.0.0.1:${server.port}
transformation.service.url=http://127.0.0.1:${server.port}
# 스케줄러 사용 여부
schedule.job.enabled = true
# 더이상 wsId가 없을때 스케줄러 시간 2 변경할지 여부
#schedule.job1.reschedule = false
# Redis 사용 여부 
spring.redis.enabled = true
# 분할 사용 여부 
dataprep.data.split.enabled = true

################################################################################

project.version = 1.0.0

async-runtime.contextPath=/api/transform

dataprep.locale=ko-KR

# Feedback
mail.smtp.to=beIRz23O6p/yqKWKtnCFxg==
mail.smtp.username=oMFJyNcCYPmgG8c+eZdS4w==
mail.smtp.from=SJ/7CwYHSaPFefC0cJ18AGKTLKWZH6gTWBCSp6D+1sM=

# Lock on preparation (mongo or none) delay in seconds
lock.preparation.store=none
lock.preparation.delay=600

spring.main.allow-bean-definition-overriding=true
spring.mvc.async.request-timeout=600000
spring.profiles.active=standalone
spring.zipkin.service.name=tdp-dataprep

# Response compression
server.compression.enabled=false
server.compression.mime-types=text/plain,application/json
# Web server port (0 = random).
#server.port=8888
server.servlet.context-path=/

# Service documentation
service.documentation.name=Talend Data Preparation
service.documentation.description=This service exposes high level services that may involve services orchestration.
service.paths=api,version,datasets,preparations,transform,apply,suggest,export

# size limit for dataset in lines (if dataset.lines > limit, dataset is truncated)
dataset.records.limit=100000
# size limit for locally imported dataset in number of bytes
dataset.local.file.size.limit=2000000000
# Sets a limit on the number of data sets to be listed
dataset.list.limit=10

# Address of the dataprep services
#dataset.service.url=http://127.0.0.1:${server.port}
#transformation.service.url=http://127.0.0.1:${server.port}
#preparation.service.url=http://127.0.0.1:${server.port}

################################################################################

# DATA SET CONTENT STORE
#    Values: local
content-service.store=local
content-service.store.local.path=${dataprep.data.home}

# In memory dataset metadata store
#dataset.metadata.store=in-memory
dataset.metadata.store=file
dataset.metadata.store.file.location=${dataprep.data.home}/store/datasets/metadata

# SMB (설정을 위한게 아니라 기존 설정되어 있는걸 읽기 위한 용도 - 분리되어 있어서...하나로 서비스시 필요없을 것 같음.)
# PREPARATION STORE
#    Values: in-memory, file
#    Example: preparation.store=file
preparation.store=file
preparation.store.file.location=${dataprep.data.home}/store/preparations/content
preparation.store.remove.hours=24

# FOLDER DATA STORE
#    values: file
folder.store=file
folder.store.file.location=${dataprep.data.home}/store/preparations/folders

# USER DATA STORE
#    Values: in-memory, file
#    Example: user.data.store=file
user.data.store=file
user.data.store.file.location=${dataprep.data.home}/store/userdata

# Where DataQuality indexes are extracted:
dataquality.indexes.file.location=${dataprep.data.semantic}

# CSV import defaults
default.import.text.enclosure=\"
default.import.text.escape=

################################################################################

server.connection-timeout=600000

#schedule.job.enabled = true
# 스케줄러 업로드 데이터셋 유형 (단일 single :: content, folders 만 공유되면됨???, 복합 complex :: complex 를 사용하기 위해서는 모든 저장소가 공유되어야 함. dataset, metadata, content, folders)
schedule.job.dataset.pattern = complex

# Redis 설정 (spring.redis.enabled 는 스케쥴러 사용시 true로 고정하던가 사용부분을 지우던가 필요, 사용여부, 캐시에 적용여부, 접속정보)
#spring.redis.enabled = true
spring.redis.transformation.enabled = false
spring.redis.host = 127.0.0.1
spring.redis.port = 6379
spring.redis.password = 1q2w3e4r

# 분할 사용 여부 (limit 이상 건수인 경우 분할할지 여부)
#dataprep.data.split.enabled = true
# Node 의 순번
#dataprep.node.no = 0
# 실제 사용할 전체 Node 의 갯수
#dataprep.node.count = 1
# Node 별 Host 정보
#dataprep.node.dataset.hosts = http://127.0.0.1:8888, http://127.0.0.1:8988
#dataprep.node.preparation.hosts = http://127.0.0.1:8888, http://127.0.0.1:8988
#dataprep.node.export.hosts = http://127.0.0.1:8888, http://127.0.0.1:8988

# Quartz Scheduler
# scheduler wait time
schedule.job.dependence.wait = 1000
# 스케줄러 업로드 데이터셋 유형 (단일 single, 복합 complex)
# CronExp
# 매일 오전 2시 
schedule.job0.cronExp = 0 0 2 * * ?
schedule.job0_2.cronExp = 0 0/5 * * * ?
# 매 1분
schedule.job1.cronExp = 0 0/1 * * * ?
# 매일 오전 3시
#schedule.job1_2.cronExp = 0 0 3 * * ?
schedule.job2.cronExp = 0 0/1 * * * ?
schedule.job3.cronExp = 0 0/1 * * * ?
schedule.job4.cronExp = 0 0/1 * * * ?

#schedule.job0.cronExp = 0 0 0 * * ?
#schedule.job1.cronExp = 0 0 2,12 * * ?
#schedule.job2.cronExp = 0 5 2,12 * * ?
#schedule.job3.cronExp = 0 10 2,12 * * ?
#schedule.job4.cronExp = 0 15 2,12 * * ?

# Hadoop
hadoop.fs.defaultFS = hdfs://127.0.0.1:9000
#hadoop.fs.defaultFS = hdfs://192.168.10.211:9000
#hadoop.fs.defaultFS = hdfs://49.50.172.155:9000
# 192.168.10.211: hadoop or profiling, 그외: root
#hadoop.user = root
#hadoop.user = profiling
hadoop.user = hadoop
hadoop.read.base.path = /kWeather/PCN
hadoop.write.base.path = /kWeather/DSHIP/Complete/Csv
hadoop.result.reg.base.path = /kWeather/DSHIP/Complete/Json

hadoop.copy.origin.base.path = /kWeather/DSHIP/Origin
hadoop.copy.write.base.path = /kWeather/DSHIP/SEJONG
#hadoop.write.sub.path =
# PCN 통합 관련 hadoop datanode 정보 변경. 
# hadoop 설정상의 포트는 9866 이나 물리적으로 1개인 서버내에서 docker로 datanode 클러스터링시
# docker 를 통해 데이터를 받는 포트는 19866, 19867, 19868 이런식이라...들어가지 못하지 때문에...
# 기본적인 테스트는 했으나 실제 붙여봐야 확인 가능할 것으로 보임. 
# 아니면...도커의 포트를 변경해서 테스트를 해보면 될 것 같으나...귀차니즘이...
# 3개의 값을 셋트로 사용하고 값이 없을때는 기본 셋팅
# 현재시점에는 1개의 정보만 보여서 단일이나...
# 클러스터링을 했을때 해당 서버의 수만큼 정보가 보인다면...수정이 필요할 수 도 있음.  
#hadoop.datanode.hostName = localhost
#hadoop.datanode.ipAddr = 127.0.0.1
#hadoop.datanode.xferPort = 9866

#hadoop.copy.recipe.base.path = /user/profiling/pipeline

# 저장 경로 (설정을 위한게 아니라 기존 설정되어 있는걸 읽기 위한 용도 - 분리되어 있어서...하나로 서비스시 필요없을 것 같음.) 
#content-service.store.local.path=/tmp/dataprep
#dataset.metadata.store.file.location=/tmp/dataprep/store/datasets/metadata
#preparation.store.file.location=/tmp/dataprep/store/preparations/content

smb.host = 192.168.10.220
smb.user = seonwons
smb.password = dhxhglap
smb.sharedDir = \uAE40\uC120\uC6D0
dataset.imports=http,local

#spring.output.ansi.enabled=always
#logging.level.org.talend=debug
#logging.level.kr.co.digitalship.dprep=debug
#logging.level.io.netty.util=debug
#logging.file=/Users/motive/Documents/workspace-sts/dataprep-run/dataprep.log
logging.config=classpath:logback.xml

# 끝열 구분자 제거(k-weather)
#kweather.preparation.replace_on_value.idx = -1
#kweather.preparation.replace_on_value.value = 
 
# 습도, 초미세먼지 도메인 변경(k-weather)
#kweather.preparation.domain_change.idx = 2, 3, 4, 5
#kweather.preparation.domain_change.value = \uBBF8\uC138\uBA3C\uC9C0, \uCD08\uBBF8\uC138\uBA3C\uC9C0, \uC628\uB3C4, \uC2B5\uB3C4
kweather.preparation.domain_change.idx = 3, 5
kweather.preparation.domain_change.value = \uCD08\uBBF8\uC138\uBA3C\uC9C0, \uC2B5\uB3C4


# 스케쥴러 Dataset 생성간...Request 동시 호출 최대 건수  
dataprep.httpUtil.counter = 30

pcn.api.enabled = true
pcn.api.host = http://api.bd.pcninc.co.kr
pcn.api.id = digitalship
pcn.api.secret = 1234

pipeline.run.enabled = true
# pipeline - sh로 호출/구동
pipeline.run.script.path = /Users/motive/Documents/workspace-sts/dataprep-external/src/main/resources
pipeline.run.script.name = shExecute.sh
#pipeline.run.script.path = /root/pipelineSh
#pipeline.run.script.name = sudo ./ProfilingPipelineStart.sh
pipeline.run.script.wait = false
# pileline - api로 호출/구동
pipeline.run.api.host = 127.0.0.1
pipeline.run.api.port = 7911
pipeline.run.api.path = /project/api/start

#spring.devtools.livereload.enabled = true

# thymeleaf 관련 설정
spring.thymeleaf.check-template-location=true
spring.thymeleaf.prefix=classpath:/templates/
#spring.thymeleaf.view-names=thymeleaf/*
spring.thymeleaf.suffix=.html
spring.thymeleaf.encoding=UTF-8
spring.thymeleaf.cache=false

# 세종대에 제공할 API 의 전처리 결과 및 메타 데이터 출력 경로(하둡)
sejong.api.export.base.path = /kWeather/SEJONG/sample
# 세종대에 제공할 API 기능중 샘플 데이터 생성에 필요한 라인수를 확인하기위한 임시 파일을 저장할 경로
sejong.api.temp.path = ${dataprep.data.home}/temp